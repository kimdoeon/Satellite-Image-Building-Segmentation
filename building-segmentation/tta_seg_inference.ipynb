{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TTA (Test Time Augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vip/anaconda3/envs/seg/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from modules.utils import load_yaml, rle_decode, rle_encode, draw_fig\n",
    "from modules.optimizer import get_optimizer\n",
    "from modules.scheduler import get_scheduler\n",
    "from modules.loss import get_loss_function\n",
    "from modules.model import get_transformers_model, get_smp_model\n",
    "from modules.dataset import transformsCustomDataset, smpDataset\n",
    "from modules.augmentation import *\n",
    "\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import argparse\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import (\n",
    "    AutoImageProcessor,\n",
    "    TrainingArguments, \n",
    "    Trainer,\n",
    "    SegformerConfig\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prj_dir = './'\n",
    "config_path = os.path.join(prj_dir, 'config', 'predict_seg_512.yaml')\n",
    "config = load_yaml(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.manual_seed(config['seed'])\n",
    "torch.manual_seed(config['seed'])\n",
    "np.random.seed(config['seed'])\n",
    "random.seed(config['seed'])\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"data/test.csv\")\n",
    "\n",
    "image_paths = []\n",
    "for img in df[\"img_path\"]:\n",
    "    path = f\"./data/test_img/{os.path.basename(img)}\"\n",
    "    image_paths.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/mit-b0 and are newly initialized: ['decode_head.linear_c.1.proj.bias', 'decode_head.linear_c.2.proj.bias', 'decode_head.linear_c.3.proj.bias', 'decode_head.linear_c.3.proj.weight', 'decode_head.linear_c.2.proj.weight', 'decode_head.classifier.weight', 'decode_head.batch_norm.num_batches_tracked', 'decode_head.linear_fuse.weight', 'decode_head.linear_c.0.proj.weight', 'decode_head.batch_norm.bias', 'decode_head.batch_norm.weight', 'decode_head.classifier.bias', 'decode_head.batch_norm.running_mean', 'decode_head.linear_c.1.proj.weight', 'decode_head.linear_c.0.proj.bias', 'decode_head.batch_norm.running_var']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = get_transformers_model(name=config['model']['name'])\n",
    "model = model.from_pretrained(\n",
    "    config['model']['weight'],\n",
    "    num_labels=1,\n",
    "    ignore_mismatched_sizes=True\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = torch.load('./results/train/20230717_135532/weights/best.pth')\n",
    "# model.load_state_dict(weights['model'])\n",
    "model.load_state_dict(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "/home/vip/anaconda3/envs/seg/lib/python3.11/site-packages/transformers/models/segformer/image_processing_segformer.py:99: FutureWarning: The `reduce_labels` parameter is deprecated and will be removed in a future version. Please use `do_reduce_labels` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "class TTA:\n",
    "    def __init__(self, transform):\n",
    "\n",
    "        self.processor = AutoImageProcessor.from_pretrained(config['processor'])\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "        self.transforms = [\n",
    "            A.VerticalFlip(p=1),\n",
    "            A.HorizontalFlip(p=1),\n",
    "            A.Compose([\n",
    "                A.HorizontalFlip(p=1),\n",
    "                A.VerticalFlip(p=1),\n",
    "            ]),\n",
    "            A.Rotate(limit=[90, 90], p=1),\n",
    "            A.Rotate(limit=[-90, -90], p=1),\n",
    "        ]\n",
    "\n",
    "    def process(self, image):\n",
    "        images = []\n",
    "\n",
    "        image = self.transform(image=image)['image']\n",
    "        inputs = self.processor(image, return_tensors='pt')\n",
    "        inputs = {k:v.squeeze(0) for k, v in inputs.items()}\n",
    "        images.append(inputs['pixel_values'])\n",
    "\n",
    "        for t in self.transforms:\n",
    "            img = self.transform(image=t(image=image)['image'])['image']\n",
    "\n",
    "            inputs = self.processor(img, return_tensors='pt')\n",
    "            inputs = {k:v.squeeze(0) for k, v in inputs.items()}\n",
    "\n",
    "            images.append(inputs['pixel_values'])\n",
    "\n",
    "        # return images\n",
    "        return torch.tensor(np.array(images), dtype=torch.float32)\n",
    "\n",
    "    def unprocess(self, images):\n",
    "        results = []\n",
    "\n",
    "        results.append(images[0])\n",
    "        results.append(self.transforms[0](image=images[1])['image'])\n",
    "        results.append(self.transforms[1](image=images[2])['image'])\n",
    "        results.append(self.transforms[2](image=images[3])['image'])\n",
    "        results.append(self.transforms[4](image=images[4])['image'])\n",
    "        results.append(self.transforms[3](image=images[5])['image'])\n",
    "\n",
    "        return results\n",
    "\n",
    "transform = A.Compose([\n",
    "    # A.Normalize(),\n",
    "    # ToTensorV2(),\n",
    "])\n",
    "\n",
    "tta = TTA(transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
     ]
    }
   ],
   "source": [
    "processor = AutoImageProcessor.from_pretrained(config['processor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upscale_logits(logit_outputs, res=224):\n",
    "    return nn.functional.interpolate(\n",
    "        logit_outputs,\n",
    "        size=(res, res),\n",
    "        mode='bilinear',\n",
    "        align_corners=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60640/60640 [1:52:44<00:00,  8.96it/s]  \n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for img_path in tqdm(image_paths):\n",
    "        image = cv2.imread(img_path)\n",
    "        images = tta.process(image)\n",
    "        images = images.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        predicts = upscale_logits(outputs.logits)\n",
    "\n",
    "        seg_prob = torch.sigmoid(predicts).detach().cpu().numpy().squeeze()\n",
    "        seg = (seg_prob > 0.5).astype(np.uint8)\n",
    "\n",
    "        tta_seg = tta.unprocess(seg)\n",
    "\n",
    "        tta_prob = (tta_seg[0] + tta_seg[1] + tta_seg[2] + tta_seg[3] + tta_seg[4] + tta_seg[5])\n",
    "        tta_image = (tta_prob >= 3.0).astype(np.uint8)\n",
    "\n",
    "        mask_rle = rle_encode(tta_image)\n",
    "        if mask_rle == '':\n",
    "            result.append(-1)\n",
    "        else:\n",
    "            result.append(mask_rle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('./data/sample_submission.csv')\n",
    "submit['mask_rle'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('./submit13.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'isSubmitted': True, 'detail': 'Success'}\n"
     ]
    }
   ],
   "source": [
    "from dacon_submit_api import dacon_submit_api \n",
    "\n",
    "result = dacon_submit_api.post_submission_file(\n",
    "    './submit13.csv', \n",
    "    '5eca29221f8e6e442f5d55ccb7455756c26e5f85a5d1aac8208a97db790bbdb9', \n",
    "    '236092', \n",
    "    'ADED', \n",
    "    ''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
