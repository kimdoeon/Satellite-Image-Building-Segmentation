{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vip/anaconda3/envs/seg/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from modules.utils import load_yaml, rle_decode, rle_encode, draw_fig\n",
    "from modules.optimizer import get_optimizer\n",
    "from modules.scheduler import get_scheduler\n",
    "from modules.loss import get_loss_function\n",
    "from modules.model import get_transformers_model, get_smp_model\n",
    "from modules.dataset import transformsCustomDataset, smpDataset\n",
    "from modules.augmentation import *\n",
    "\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import argparse\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prj_dir = './'\n",
    "config_path = os.path.join(prj_dir, 'config', 'predict_smp_512.yaml')\n",
    "config = load_yaml(config_path)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test len: 60640\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(f\"data/test.csv\")\n",
    "\n",
    "images = []\n",
    "for img in df[\"img_path\"]:\n",
    "    path = f\"./data/test_img/{os.path.basename(img)}\"\n",
    "    images.append(path)\n",
    "\n",
    "print('test len:', len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transfrom = A.Compose([\n",
    "    A.Equalize(),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "test_dataset = smpDataset(images=images, \n",
    "                          masks=None, \n",
    "                          transform=test_transfrom, \n",
    "                          infer=True)\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, \n",
    "                              batch_size=config['batch_size'], \n",
    "                              num_workers=config['num_workers'],\n",
    "                              shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_smp_model(name=config['model']['architecture'])\n",
    "\n",
    "model = model(encoder_name=config['model']['encoder'],\n",
    "              encoder_weights=config['model']['encoder_weight'],\n",
    "              in_channels=config['model']['in_channel'],\n",
    "              classes=config['model']['n_classes'],\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "weights = torch.load(config['model']['pretrained'])\n",
    "model.load_state_dict(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1895/1895 [04:40<00:00,  6.76it/s]\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for idx, (images, filenames) in enumerate(tqdm(test_dataloader)):\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        seg_prob = torch.sigmoid(outputs).detach().cpu().numpy().squeeze()\n",
    "        seg = (seg_prob > 0.5).astype(np.uint8)\n",
    "        \n",
    "        for i in range(len(images)):\n",
    "            mask_rle = rle_encode(seg[i])\n",
    "            if mask_rle == '':\n",
    "                result.append(-1)\n",
    "            else:\n",
    "                result.append(mask_rle)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('./data/sample_submission.csv')\n",
    "submit['mask_rle'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('./submit3.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
